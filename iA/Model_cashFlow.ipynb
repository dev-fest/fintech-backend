{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger toutes les tables en DataFrames (modifiez le chemin si vous utilisez des fichiers JSON)\n",
    "cashflow_df = pd.read_json('CashFlow.json')\n",
    "expenses_df = pd.read_json('Expenses.json')\n",
    "revenue_df = pd.read_json('Revenue.json')\n",
    "investments_df = pd.read_json('Investments.json')\n",
    "funding_df = pd.read_json('Funding.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "def augment_expenses(df, num_augments=5):\n",
    "    augmented_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_augments):\n",
    "            # Modifier le montant ±10%\n",
    "            new_amount = row[\"amount_expenses\"] * random.uniform(0.9, 1.1)\n",
    "\n",
    "            # Décaler la date de ±7 jours\n",
    "            new_date = pd.to_datetime(row[\"date\"]) + timedelta(days=random.randint(-7, 7))\n",
    "\n",
    "            # Ajouter l'entrée augmentée\n",
    "            augmented_data.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"date\": new_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"amount_expenses\": round(new_amount, 2),\n",
    "                \"expense_category\": row[\"expense_category\"],\n",
    "                \"department\": row[\"department\"],\n",
    "                \"description\": row[\"description\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "def augment_revenue(df, num_augments=5):\n",
    "    augmented_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_augments):\n",
    "            # Modifier le montant ±15%\n",
    "            new_amount = row[\"amount_revenue\"] * random.uniform(0.85, 1.15)\n",
    "\n",
    "            # Décaler la date de ±10 jours\n",
    "            new_date = pd.to_datetime(row[\"date\"]) + timedelta(days=random.randint(-10, 10))\n",
    "\n",
    "            # Ajouter l'entrée augmentée\n",
    "            augmented_data.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"date\": new_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"amount_revenue\": round(new_amount, 2),\n",
    "                \"product_line\": row[\"product_line\"],\n",
    "                \"customer_type\": row[\"customer_type\"],\n",
    "                \"description\": row[\"description\"]\n",
    "            })\n",
    "    return pd.DataFrame(augmented_data)\n",
    "def augment_investments(df, num_augments=5):\n",
    "    augmented_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_augments):\n",
    "            # Modifier le montant d'investissement et la valeur actuelle ±10%\n",
    "            new_investment_amount = row[\"investment_amount\"] * random.uniform(0.9, 1.1)\n",
    "            new_value = row[\"current_value\"] * random.uniform(0.9, 1.1)\n",
    "\n",
    "            # Décaler la date de ±15 jours\n",
    "            new_date = pd.to_datetime(row[\"date\"]) + timedelta(days=random.randint(-15, 15))\n",
    "\n",
    "            # Ajouter l'entrée augmentée\n",
    "            augmented_data.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"investment_type\": row[\"investment_type\"],\n",
    "                \"investment_amount\": round(new_investment_amount, 2),\n",
    "                \"date\": new_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"returns\": row[\"returns\"],\n",
    "                \"risk_level\": row[\"risk_level\"],\n",
    "                \"current_value\": round(new_value, 2),\n",
    "                \"description\": row[\"description\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "def augment_funding(df, num_augments=5):\n",
    "    augmented_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_augments):\n",
    "            # Modifier le montant levé et l'évaluation ±10%\n",
    "            new_amount_raised = row[\"amount_raised\"] * random.uniform(0.9, 1.1)\n",
    "            new_valuation = row[\"valuation\"] * random.uniform(0.9, 1.1)\n",
    "\n",
    "            # Décaler la date de ±20 jours\n",
    "            new_date = pd.to_datetime(row[\"date\"]) + timedelta(days=random.randint(-20, 20))\n",
    "\n",
    "            # Ajouter l'entrée augmentée\n",
    "            augmented_data.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"funding_round\": row[\"funding_round\"],\n",
    "                \"amount_raised\": round(new_amount_raised, 2),\n",
    "                \"date\": new_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"investor_name\": row[\"investor_name\"],\n",
    "                \"valuation\": round(new_valuation, 2),\n",
    "                \"description\": row[\"description\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(augmented_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenses_aug = augment_expenses(expenses_df,500)\n",
    "revenue_aug = augment_revenue(revenue_df,500)\n",
    "investments_aug = augment_investments(investments_df,500)\n",
    "funding_aug = augment_funding(funding_df,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.44 GiB for an array with shape (1, 327689378) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(cashflow_df, revenue_aug[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount_revenue\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_revenue\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, expenses_aug[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount_expenses\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_expenses\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, investments_aug[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvestment_amount\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, funding_aug[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount_raised\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Remplacer NaN par 0 dans les colonnes numériques\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:811\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    809\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 811\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    813\u001b[0m )\n\u001b[0;32m    814\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:802\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    800\u001b[0m left\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m llabels\n\u001b[0;32m    801\u001b[0m right\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m rlabels\n\u001b[1;32m--> 802\u001b[0m result \u001b[38;5;241m=\u001b[39m concat([left, right], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:204\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _concat_managers_axis0(mgrs_indexers, axes, copy)\n\u001b[0;32m    206\u001b[0m mgrs_indexers \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    208\u001b[0m concat_plans \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    209\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[38;5;28;01mfor\u001b[39;00m mgr, indexers \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers\n\u001b[0;32m    210\u001b[0m ]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:279\u001b[0m, in \u001b[0;36m_concat_managers_axis0\u001b[1;34m(mgrs_indexers, axes, copy)\u001b[0m\n\u001b[0;32m    277\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy:\n\u001b[1;32m--> 279\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# by slicing instead of copy(deep=False), we get a new array\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m#  object, see test_concat_copy\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mgetitem_block(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:540\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    538\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 540\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    541\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.44 GiB for an array with shape (1, 327689378) and data type float64"
     ]
    }
   ],
   "source": [
    "# Conversion explicite des colonnes 'date' au format datetime64[ns]\n",
    "cashflow_df['date'] = pd.to_datetime(cashflow_df['date'])  \n",
    "cashflow_df['date'] = cashflow_df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "revenue_aug['date'] = pd.to_datetime(revenue_aug['date'])\n",
    "revenue_aug['date'] = revenue_aug['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "expenses_aug['date'] = pd.to_datetime(expenses_aug['date'])\n",
    "expenses_aug['date'] = expenses_aug['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "investments_aug['date'] = pd.to_datetime(investments_aug['date'])\n",
    "investments_aug['date'] = investments_aug['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "funding_aug['date'] = pd.to_datetime(funding_aug['date'], errors='coerce')\n",
    "funding_aug['date'] = funding_aug['date'].dt.strftime('%Y-%m-%dz')\n",
    "\n",
    "\n",
    "# Merge par date pour combiner cashflow, revenue, expenses et autres\n",
    "df = pd.merge(cashflow_df, revenue_aug[['date', 'amount_revenue']], on='date', how='left', suffixes=('', '_revenue'))\n",
    "df = pd.merge(df, expenses_aug[['date', 'amount_expenses']], on='date', how='left', suffixes=('', '_expenses'))\n",
    "df = pd.merge(df, investments_aug[['date', 'investment_amount']], on='date', how='left')\n",
    "df = pd.merge(df, funding_aug[['date', 'amount_raised']], on='date', how='left')\n",
    "\n",
    "# Remplacer NaN par 0 dans les colonnes numériques\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Affichage des données consolidées\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Caractéristiques et cibles\n",
    "X = df[['amount_revenue', 'amount_expenses', 'investment_amount', 'amount_raised']]\n",
    "y_inflow = df['cash_inflow']\n",
    "y_outflow = df['cash_outflow']\n",
    "y_netflow = df['net_cash_flow']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_inflow_train, y_inflow_test = train_test_split(X, y_inflow, test_size=0.2, random_state=42)\n",
    "_, _, y_outflow_train, y_outflow_test = train_test_split(X, y_outflow, test_size=0.2, random_state=42)\n",
    "_, _, y_netflow_train, y_netflow_test = train_test_split(X, y_netflow, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialiser les modèles\n",
    "model_inflow = LinearRegression()\n",
    "model_outflow = LinearRegression()\n",
    "model_netflow = LinearRegression()\n",
    "\n",
    "# Entraîner les modèles\n",
    "model_inflow.fit(X_train, y_inflow_train)\n",
    "model_outflow.fit(X_train, y_outflow_train)\n",
    "model_netflow.fit(X_train, y_netflow_train)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inflow - MSE: 111404349.05, R²: 0.15\n",
      "Outflow - MSE: 13305578.09, R²: 0.14\n",
      "Net Flow - MSE: 114756846.07, R²: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prédictions\n",
    "y_inflow_pred = model_inflow.predict(X_test)\n",
    "y_outflow_pred = model_outflow.predict(X_test)\n",
    "y_netflow_pred = model_netflow.predict(X_test)\n",
    "\n",
    "# Calculer les MSE et R² Score\n",
    "print(f\"Inflow - MSE: {mean_squared_error(y_inflow_test, y_inflow_pred):.2f}, R²: {r2_score(y_inflow_test, y_inflow_pred):.2f}\")\n",
    "print(f\"Outflow - MSE: {mean_squared_error(y_outflow_test, y_outflow_pred):.2f}, R²: {r2_score(y_outflow_test, y_outflow_pred):.2f}\")\n",
    "print(f\"Net Flow - MSE: {mean_squared_error(y_netflow_test, y_netflow_pred):.2f}, R²: {r2_score(y_netflow_test, y_netflow_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Cash Inflow: 58030.31\n",
      "Predicted Cash Outflow: 16344.37\n",
      "Predicted Net Cash Flow: 41685.94\n"
     ]
    }
   ],
   "source": [
    "# Exemple de nouvelles données\n",
    "new_data = pd.DataFrame({\n",
    "    'amount_revenue': [100000],\n",
    "    'amount_expenses': [40000],\n",
    "    'investment_amount': [5000],\n",
    "    'amount_raised': [20000]\n",
    "})\n",
    "\n",
    "# Prédire les flux de trésorerie\n",
    "predicted_inflow = model_inflow.predict(new_data)\n",
    "predicted_outflow = model_outflow.predict(new_data)\n",
    "predicted_netflow = model_netflow.predict(new_data)\n",
    "\n",
    "print(f\"Predicted Cash Inflow: {predicted_inflow[0]:.2f}\")\n",
    "print(f\"Predicted Cash Outflow: {predicted_outflow[0]:.2f}\")\n",
    "print(f\"Predicted Net Cash Flow: {predicted_netflow[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
